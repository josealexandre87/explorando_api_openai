{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "import openai\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "\n",
    "_ = load_dotenv(find_dotenv())\n",
    "\n",
    "client = openai.Client()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def obter_temperatura_atual(local, unidade=\"celcius\"): # a função está HardCode. Poderia ser uma API.\n",
    "    if \"são paulo\" in local.lower():\n",
    "        return json.dumps(\n",
    "        {\"local\": \"São Paulo\", \"temperatura\": \"32\", \"unidade\": unidade}\n",
    "        )\n",
    "    elif \"porto alegre\" in local.lower():\n",
    "        return json.dumps(\n",
    "            {\"local\": \"Porto Alegre\", \"temperatura\": \"25\", \"unidade\": unidade}\n",
    "        )\n",
    "    elif \"rio de janeiro\" in local.lower():\n",
    "        return json.dumps(\n",
    "            {\"local\": \"Rio de Janeiro\", \"temperatura\": \"35\", \"unidade\": unidade}\n",
    "        )\n",
    "    else:\n",
    "        return json.dumps(\n",
    "            {\"local\": local, \"temperatura\": \"unknown\"}\n",
    "        ) # json.dumps -> pega um dicionário e transforma em um json.\n",
    "#---\n",
    "tools = [ #Temos que descrever para o modelo tudo sobre as Ferramentas/Tools que ele tem para usar!\n",
    "    {\n",
    "        \"type\": \"function\",\n",
    "        \"function\": {\n",
    "            \"name\": \"obter_temperatura_atual\", #importante para o modelo saber a descrição explicita da função!\n",
    "            \"description\": \"Obtém a temperatura atual em uma dada cidade\",\n",
    "            \"parameters\": {\n",
    "                \"type\": \"object\",\n",
    "                \"properties\": {#são os parâmetros da função! def obter_temperatura_atual(local, unidade=\"celcius\")\n",
    "                    \"local\": {\n",
    "                        \"type\": \"string\",\n",
    "                        \"description\": \"O nome da cidade. Ex: São Paulo\",\n",
    "                    },\n",
    "                    \"unidade\": {\n",
    "                        \"type\": \"string\",\n",
    "                        \"enum\": [\"celcius\", \"fahrenheit\"]\n",
    "                    },\n",
    "                },\n",
    "                \"required\": [\"local\"], #parâmetro que vai ser solicitado!\n",
    "            },\n",
    "        },\n",
    "    }\n",
    "]\n",
    "#---\n",
    "funcoes_disponiveis = { # apenas para facilitar a procura das ferramentas/tools existem!\n",
    "    \"obter_temperatura_atual\": obter_temperatura_atual,\n",
    "}\n",
    "\n",
    "mensagens = [\n",
    "    {\"role\": \"user\",\n",
    "    \"content\": \"Qual é a temperatura em São Paulo e Porto Alegre?\"}\n",
    "]\n",
    "\n",
    "resposta = client.chat.completions.create(\n",
    "    model=\"gpt-3.5-turbo-0125\",\n",
    "    messages=mensagens,\n",
    "    tools=tools,\n",
    "    tool_choice=\"auto\",\n",
    "    )\n",
    "#---\n",
    "mensagem_resp = resposta.choices[0].message\n",
    "tool_calls = mensagem_resp.tool_calls\n",
    "\n",
    "if tool_calls:\n",
    "    mensagens.append(mensagem_resp)\n",
    "    for tool_call in tool_calls:\n",
    "        function_name = tool_call.function.name\n",
    "        function_to_call = funcoes_disponiveis[function_name]\n",
    "        function_args = json.loads(tool_call.function.arguments)\n",
    "        function_response = function_to_call(\n",
    "            local=function_args.get(\"local\"),\n",
    "            unidade=function_args.get(\"unidade\"),\n",
    "        )\n",
    "        mensagens.append(\n",
    "            {\n",
    "                \"tool_call_id\": tool_call.id,\n",
    "                \"role\": \"tool\",\n",
    "                \"name\": function_name,\n",
    "                \"content\": function_response,\n",
    "            }\n",
    "        )\n",
    "    segunda_resposta = client.chat.completions.create(\n",
    "        model=\"gpt-3.5-turbo-0125\",\n",
    "        messages=mensagens,\n",
    "    )\n",
    "\n",
    "mensagens_resp = segunda_resposta.choices[0].message\n",
    "print(mensagem_resp.content)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
